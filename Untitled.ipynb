{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f34b361-e379-4a34-8a16-51619752a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import fitz\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9fa53d-bec6-43cb-bf3c-e05d6f86359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(content, folder_path, filename,):\n",
    "    try:\n",
    "        if content is not None:\n",
    "            # Create the folder if it doesn't exist\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Write the content to the file\n",
    "            with open(file_path,'w', encoding='utf-8') as file:\n",
    "            #     file.write(content)\n",
    "            # Split the text into lines and write each line with a newline character\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines:\n",
    "                    file.write(line.strip())  # Remove leading/trailing whitespaces\n",
    "                    file.write('\\n')  # Add a newline character\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to file. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac3a5ff-3f29-4a01-b452-ae825aac51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_html_file(html_file_path):\n",
    "    try:\n",
    "        with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            text_content = soup.get_text(separator='\\n')\n",
    "            result = text_content.split('\\n')\n",
    "            result = [x for x in result if x != '']\n",
    "            return \"\\n\".join(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract text from {html_file_path}. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d462aff7-9c50-4268-8637-ddec0a4666e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html_files(folder_path):\n",
    "    text_folder = os.path.join(folder_path, 'html_text_files')\n",
    "\n",
    "    # Create a folder to store text files if it doesn't exist\n",
    "    os.makedirs(text_folder, exist_ok=True)\n",
    "\n",
    "    # Loop through HTML files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".html\"):\n",
    "            html_file_path = os.path.join(folder_path, filename)\n",
    "            # Extract text from HTML file\n",
    "            extracted_text = extract_text_from_html_file(html_file_path)\n",
    "            \n",
    "            text_folder = os.path.join(folder_path, 'html_text_files')\n",
    "            save_to_file(extracted_text, text_folder, filename + \"_extracted_text.txt\")\n",
    "        \n",
    "            # if extracted_text:\n",
    "            #     # Generate a filename for the text file\n",
    "            #     text_filename = os.path.splitext(filename)[0] + \"_extracted_text.txt\"\n",
    "\n",
    "            #     # Save the extracted text to a text file\n",
    "            #     text_file_path = os.path.join(text_folder, text_filename)\n",
    "            #     with open(text_file_path, 'w', encoding='utf-8') as text_file:\n",
    "            #         text_file.write(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b3137e-40b3-4018-ac60-bf39844ba78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_14519de1f15c9d75bcb837a42ca22576_press_release_drax-welcomes-cccs-call-for-faster-progress-in-delivering-uk-carbon-removals-and-confirms-decommissioning-of-coal-units-will-continue__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_2cbcf41ab8e5135c0a2d3f9d9abb9617_investors_publication-circular-notice-general-meeting-relation-proposed-acquisition-flexible-low-carbon-renewable-uk-power-generation-iberdrola__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_524279b4cb762b3fac9353ca6d64cdfb_press_release_drax-power-ceo-andy-koss-says-innovation-transform-regions-energy-sector-northern-powerhouse-partnership-releases-prime-capabilities-report__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_59de5e6881d87d279f678466e592de53_press_release_drax-power-ceo-andy-koss-says-innovation-transform-regions-energy-sector-northern-powerhouse-partnership-releases-prime-capabilities-report__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_75e00ede2f97c0624fadc5abcab9d016_investors_publication-circular-notice-general-meeting-relation-proposed-acquisition-flexible-low-carbon-renewable-uk-power-generation-iberdrola__html.html_extracted_text.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surya Teja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_92c78b76dc2336421620cce8eefbf20c_press_release_negative-emissions-pioneer-drax-and-leading-global-carbon-capture-company-mitsubishi-heavy-industries-group-announce-new-beccs-pilot__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_ac0e127209b8271dfba2d3d9e517f311_press_release_drax-welcomes-cccs-call-for-faster-progress-in-delivering-uk-carbon-removals-and-confirms-decommissioning-of-coal-units-will-continue__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_c0e0a9592a9a67a326d6f477d8789363_press_release_energy-white-paper-recognises-negative-emissions-and-sustainable-biomass-as-a-vital-technology-to-achieve-net-zero-drax-group-ceo__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_c452bee976f6b007f62dbdd31f4e8c2e_press_release_energy-white-paper-recognises-negative-emissions-and-sustainable-biomass-as-a-vital-technology-to-achieve-net-zero-drax-group-ceo__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_ca11125c7276a5225a58235e49fe9c29_press_release_negative-emissions-pioneer-drax-and-leading-global-carbon-capture-company-mitsubishi-heavy-industries-group-announce-new-beccs-pilot__html.html_extracted_text.txt'\n",
      "Error saving to file. Error: [Errno 2] No such file or directory: 'D:\\\\Intern\\\\crawled_data\\\\html_files\\\\html_text_files\\\\crawled_e6d0aa0a4f64114a620c4c7b7d9f38a7_press_release_drax-announces-partnership-with-federation-of-southern-cooperatives-to-drive-equal-access-to-us-forestry-for-african-american-landowners__html.html_extracted_text.txt'\n"
     ]
    }
   ],
   "source": [
    "process_html_files('D:\\Acuration\\crawled_data\\html_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29322ee-e934-424f-9948-a2fd65907d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
